<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <link rel="icon" type="image/svg+xml" href="/vite.svg" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Compute Phase Shift</title>
</head>

<body>
  <!-- Non-JavaScript Fallback -->
  <noscript>
    <div style="
        max-width: 1200px; 
        margin: 2rem auto; 
        padding: 2rem; 
        font-family: system-ui, sans-serif;
        line-height: 1.6;
        background: #f9f9f9;
        border-radius: 8px;
      ">
      <h1 style="color: #1a1a1a; margin-bottom: 1rem;">AI Compute Phase Shift</h1>
      <p style="color: #666; margin-bottom: 2rem;">
        <strong>Note:</strong> This visualization requires JavaScript for interactive features.
        Below is a static snapshot of the complete visualization.
      </p>

      <!-- Static Image Fallback -->
      <div style="margin: 2rem 0; text-align: center; background: white; padding: 1rem; border-radius: 8px;">
        <img src="/ai_compute_timeline_highres.png"
          alt="AI Compute Timeline: Chart showing exponential growth from 1900 (1 FLOP) to 2024 (5×10^25 FLOPs). Orange dots represent historical computing milestones following Moore's Law. Purple dots show deep learning models breaking from the trend after 2012. The logarithmic scale compresses the massive differences, with GPT-4 and Gemini Ultra at the top representing compute equivalent to hundreds of millions of human lifetimes."
          style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);" />
      </div>

      <h2 style="color: #1a1a1a; font-size: 1.5rem; margin-top: 2rem;">Key Milestones</h2>
      <ul style="color: #444;">
        <li><strong>1900</strong> - Human Baseline: 1 FLOP (calculation per second)</li>
        <li><strong>1945</strong> - ENIAC: 10<sup>5</sup> FLOPs (100,000× human)</li>
        <li><strong>1997</strong> - Deep Blue: 10<sup>12</sup> FLOPs (chess supercomputer)</li>
        <li><strong>2012</strong> - AlexNet: 10<sup>18</sup> FLOPs (deep learning breakthrough)</li>
        <li><strong>2016</strong> - AlphaGo: 10<sup>23</sup> FLOPs (defeats world champion)</li>
        <li><strong>2023</strong> - GPT-4: 2×10<sup>25</sup> FLOPs (600 million human lifetimes)</li>
        <li><strong>2024</strong> - Gemini Ultra: 5×10<sup>25</sup> FLOPs (all humans since dinosaurs)</li>
      </ul>

      <h2 style="color: #1a1a1a; font-size: 1.5rem; margin-top: 2rem;">Understanding the Scale</h2>
      <p style="color: #444;">
        The chart above uses a <strong>logarithmic scale</strong> to compress the massive range of values.
        Each step up represents a 10× increase in compute power.
      </p>
      <p style="color: #444;">
        AI training compute grew from <strong>1 calculation/second</strong> (human, 1900)
        to <strong>50 septillion calculations</strong> (5×10<sup>25</sup> FLOPs, Gemini Ultra 2024).
      </p>
      <p style="color: #444; font-weight: 500; padding: 1rem; background: #fff; border-radius: 4px;">
        This is a <strong>10<sup>25</sup>-fold increase</strong> — a phase shift that broke from Moore's Law
        in 2012 with GPU-accelerated deep learning. The purple dots no longer follow the orange trend line.
      </p>

      <p style="margin-top: 2rem; padding: 1rem; background: #fff; border-left: 4px solid #BD10E0;">
        <strong>Enable JavaScript</strong> to experience the full interactive version with 35 compute milestones,
        logarithmic/linear scale toggle, speculative 2025-2026 estimates, and detailed tooltips on hover.
      </p>
    </div>
  </noscript>

  <div id="app"></div>
  <script type="module" src="/src/main.js"></script>
</body>

</html>